{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load up experiment & annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/mp-mental-health/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "import file_handling\n",
    "from indoor_positioning import get_beacons_for_proximity_approach, get_file_as_data_frame\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from classification.classification import classify_all\n",
    "from data_reading.phyphox import read_experiment\n",
    "from features import extract_timeseries_features\n",
    "from file_handling import get_sub_directories\n",
    "from preprocessing import align_data, segment_windows, merge_left_and_right_chunk, set_time_delta_as_index\n",
    "from visualization import plot_duration_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/marvinmirtschin/Documents/master-project/mp-mental-health-2020/src/preprocessing/_data_frame.py:31: FutureWarning: Passing datetime64-dtype data to TimedeltaIndex is deprecated, will raise a TypeError in a future version\n",
      "  time_delta_index = pd.TimedeltaIndex(timestamp_to_date, unit=output_timestamp_unit)\n",
      "/opt/anaconda3/envs/mp-mental-health/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: No files matched the given pattern: ../../data/phyphox/full recordings/Cilly/**/*.json\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "experiment_dir_path = \"../../data/phyphox/full recordings/\"\n",
    "experiment_dirs = get_sub_directories(experiment_dir_path)\n",
    "# complete_experiments_indices = [1,2,3,5,7]\n",
    "# experiment_dirs = [experiment_dirs[i] for i in complete_experiments_indices]\n",
    "sample_rate = 50\n",
    "chunks = {\"right\": [], \"left\": [], \"indoor\": []}\n",
    "null_chunks = {\"right\": [], \"left\": [], \"indoor\": []}\n",
    "y_columns = [\"start\", \"end\", \"label\", \"hand\"]\n",
    "y = pd.DataFrame(columns=y_columns)\n",
    "#del experiment_dirs[1]\n",
    "for directory in experiment_dirs:\n",
    "    offsets = {}\n",
    "\n",
    "    try:\n",
    "        with open(directory + \"/offset.txt\") as f:\n",
    "            for line in f:\n",
    "                (key, val) = line.split(\": \")\n",
    "                offsets[key.lower()] = val\n",
    "    except FileNotFoundError as e:\n",
    "        continue\n",
    "\n",
    "    data_frames = read_experiment(directory, offsets=offsets)\n",
    "    data_frames = {key : align_data(data_frame, listening_rate=1000/sample_rate, reference_sensor=None) for key, data_frame in data_frames.items()}\n",
    "    \n",
    "    try:\n",
    "        indoor_file = file_handling.get_file_names_in_directory_for_pattern(directory, \"*.json\")[0]\n",
    "        indoor_data_frame = get_file_as_data_frame(indoor_file)\n",
    "        \n",
    "        # filter out incorrect placed beacons\n",
    "        indoor_data_frame = indoor_data_frame[indoor_data_frame[\"minor\"] != 2]\n",
    "        indoor_data_frame = indoor_data_frame[indoor_data_frame[\"minor\"] != 10]\n",
    "        \n",
    "        new_df = get_beacons_for_proximity_approach(indoor_data_frame)\n",
    "        indoor_data_frame = new_df\n",
    "        indoor_data_frame = set_time_delta_as_index(indoor_data_frame, origin_timestamp_unit='ms',\n",
    "                                             output_timestamp_unit=\"milliseconds\",\n",
    "                                             timestamp_key=\"timestamp\")\n",
    "        indoor_data_frame.sort_index(inplace=True)\n",
    "        # TODO: filter out minor 2 and 10 for now\n",
    "        # TODO: align needs to be done on aggregated data\n",
    "        # TODO: do we really need alignment -> for now yes\n",
    "        data_frames[\"indoor\"] = align_data(indoor_data_frame, interpolation_method=\"previous\", listening_rate=1000/sample_rate, reference_sensor=None)\n",
    "        del indoor_data_frame\n",
    "        del new_df\n",
    "        del indoor_file\n",
    "    except IndexError:\n",
    "        # we don't have an indoor recording for this recording session\n",
    "        continue\n",
    "\n",
    "    y_user = pd.read_csv(directory + \"/annotations.tsv\", delimiter=\"\\t\", header=None)\n",
    "    hands = pd.read_csv(directory + \"/hands.tsv\", delimiter=\"\\t\", header=None)\n",
    "    y_user = y_user.iloc[:, [3,5,8]]\n",
    "    hands = hands.iloc[:, [8]]\n",
    "    y_user = pd.concat([y_user, hands], axis=1)\n",
    "    y_user.columns = y_columns\n",
    "    y = pd.concat([y, y_user], axis=0)\n",
    "\n",
    "    # iterate over the annotations and split the timeseries in chunks\n",
    "    for key, df in data_frames.items():\n",
    "        if key in chunks:\n",
    "            chunks[key] += [df.iloc[int(annotation[\"start\"]*sample_rate):int(annotation[\"end\"]*sample_rate)] for i, annotation in y_user.iterrows()]\n",
    "            # null chunks are everything in between annotations\n",
    "            null_chunks[key] += [df.iloc[int(annotation[\"end\"]*sample_rate):int(y_user.iloc[i+1:i+2][\"start\"]*sample_rate)] for i, annotation in y_user.iterrows() if i < len(y_user)-1]\n",
    "            \n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_dirs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_duration_histogram(chunks[\"right\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_duration_histogram(null_chunks[\"right\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/opt/anaconda3/envs/mp-mental-health/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# append the activity label (as int) and the action id to the dataframe\n",
    "# we need to do this to be able to extract time series features later\n",
    "\n",
    "labels = y.loc[:, \"label\"].unique()\n",
    "label_ids = { l: i for l,i in zip(labels, range(0,len(labels))) }\n",
    "\n",
    "# list of tuples (left chunk, right chunk)\n",
    "chunks_two_handed = []\n",
    "# list of chunks\n",
    "chunks_one_handed = []\n",
    "\n",
    "y = y.replace(label_ids)\n",
    "\n",
    "for i, cl in zip(range(len(y)), y.iterrows()):\n",
    "    label_id = int(cl[1][\"label\"])\n",
    "    action_id = i\n",
    "    two_handed_chunk = []\n",
    "    for hand, current_chunk_data_list in chunks.items():\n",
    "        \n",
    "        # TODO: handle indoor here\n",
    "        if hand == \"indoor\":\n",
    "            continue\n",
    "\n",
    "        current_chunk = current_chunk_data_list[i]\n",
    "        chunk_hand = cl[1][\"hand\"]\n",
    "        two_handed_chunk.append(current_chunk)\n",
    "        one_handed_chunk = current_chunk\n",
    "        one_handed_chunk[\"action_id\"] = action_id\n",
    "        if chunk_hand == hand:\n",
    "            #c[\"activity\"] = label_id\n",
    "            chunks_one_handed.append(one_handed_chunk)\n",
    "    two_handed_chunk = merge_left_and_right_chunk(two_handed_chunk[0], two_handed_chunk[1], action_id)\n",
    "    chunks_two_handed.append(two_handed_chunk)\n",
    "\n",
    "labels = y.loc[:, \"label\"].squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature extraction for 2 handed activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "window_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# prepare null chunks\n",
    "null_class_chunks = []\n",
    "\n",
    "# TODO: assert that this list is disjoint to the list of action ids from activities\n",
    "null_action_ids = range(len(chunks_two_handed),len(chunks_two_handed)+len(null_chunks[\"right\"]))\n",
    "for c_r, c_l, action_id in zip(null_chunks[\"right\"], null_chunks[\"left\"], null_action_ids):\n",
    "    if len(c_l):\n",
    "        c_both = merge_left_and_right_chunk(c_l, c_r, action_id)\n",
    "        null_class_chunks.append(c_both)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chunks_two_handed[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification step 1: OCD activities vs null class samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/Users/marvinmirtschin/Documents/master-project/mp-mental-health-2020/src/preprocessing/_segmentation.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c_new[\"action_id\"] = [(action_id, i)] * len(c_new)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# new label id for ocd activities\n",
    "labels_ocd_acts = pd.Series([labels.max()+2] * len(chunks_two_handed))\n",
    "chunks_ocd_activities, labels_ocd_acts = segment_windows(chunks_two_handed, labels_ocd_acts.to_numpy(), window_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chunks_ocd_activities[9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# TODO: add indoor to segment_windows\n",
    "null_labels = pd.Series([labels.max()+1] * len(null_class_chunks))\n",
    "null_class_chunks, null_labels = segment_windows(null_class_chunks, null_labels.to_numpy(), window_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "null_class_chunks[9]\n",
    "\n",
    "# TODO: assert that len(null_class_chunks.columns) == len(chunks_ocd_activities.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature extraction for OCD activities vs non-OCD activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/opt/anaconda3/envs/mp-mental-health/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "null_classification_concat = pd.concat(chunks_ocd_activities + null_class_chunks).reset_index(drop=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_two_handed_null_test = extract_timeseries_features(null_classification_concat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection for OCD activities vs non-OCD activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_null_classification = pd.concat([labels_ocd_acts, null_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_null_classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "impute(features_two_handed_null_test)\n",
    "X_two_handed_selected_null_test = select_features(features_two_handed_null_test, labels_null_classification)\n",
    "# Add indoor\n",
    "X_two_handed_selected_null_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: feature visualization: scatter plot - explain what happens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_null_classification = scaler.fit_transform(X_two_handed_selected_null_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train models and score results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Two handed classification\")\n",
    "classify_all(X_null_classification, labels_null_classification)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: plot feature importance (which feature has the most impact on the results)\n",
    "\n",
    "sns.pairplot(X_null_classification[:, :10])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chunks_two_handed_segmented, labels = segment_windows(chunks_two_handed, labels.to_numpy(), window_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature extraction for 2 handed classifier of activities against each other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.concat(chunks_two_handed).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_two_handed = extract_timeseries_features(pd.concat(chunks_two_handed).reset_index(drop=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_two_handed.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features_two_handed.dropna(inplace=True, axis=1)\n",
    "features_two_handed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature selection for 2 handed classifier of activities against each other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Off-the-shelve feature selection from tsfresh\n",
    "\n",
    "impute(features_two_handed)\n",
    "X_two_handed_selected = select_features(features_two_handed, pd.Series(labels))\n",
    "X_two_handed_selected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X_two_handed_selected)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "X_two_handed_selected = sel.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X_two_handed_selected = SelectKBest(f_classif, k=2000).fit_transform(X, labels)\n",
    "X_two_handed_selected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train models and score results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Two handed classification\")\n",
    "classify_all(X, labels, label_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}