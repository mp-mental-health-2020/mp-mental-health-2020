{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load up experiment & annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julio/Documents/Uni/5_Master/Master Project/mp-mental-health-2020/src/preprocessing/_data_frame.py:31: FutureWarning: Passing datetime64-dtype data to TimedeltaIndex is deprecated, will raise a TypeError in a future version\n",
      "  time_delta_index = pd.TimedeltaIndex(timestamp_to_date, unit=output_timestamp_unit)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_reading.phyphox import read_experiment\n",
    "from preprocessing._interpolation import align_data\n",
    "from file_handling import get_sub_directories\n",
    "\n",
    "experiment_dir_path = \"../../data/phyphox/short recordings/\"\n",
    "experiment_dirs = get_sub_directories(experiment_dir_path)\n",
    "\n",
    "sample_rate = 50\n",
    "chunks = {\"right\": [], \"left\": []}\n",
    "y_columns = [\"start\", \"end\", \"label\", \"hand\"]\n",
    "y = pd.DataFrame(columns=y_columns)\n",
    "#del experiment_dirs[1]\n",
    "for dir in experiment_dirs[1:3]:\n",
    "    offsets = {}\n",
    "    with open(dir + \"/offset.txt\") as f:\n",
    "        for line in f:\n",
    "           (key, val) = line.split(\": \")\n",
    "           offsets[key] = val\n",
    "\n",
    "    data_frames = read_experiment(dir, offsets=offsets)\n",
    "    data_frames = {key : align_data(data_frame, listening_rate=1000/sample_rate, reference_sensor=None) for key, data_frame in data_frames.items()}\n",
    "\n",
    "    y_user = pd.read_csv(dir + \"/annotations.tsv\", delimiter=\"\\t\", header=None)\n",
    "    hands = pd.read_csv(dir + \"/hands.tsv\", delimiter=\"\\t\", header=None)\n",
    "    y_user = y_user.iloc[:, [3,5,8]]\n",
    "    hands = hands.iloc[:, [8]]\n",
    "    y_user = pd.concat([y_user, hands], axis=1)\n",
    "    y_user.columns = y_columns\n",
    "    y = pd.concat([y, y_user], axis=0)\n",
    "\n",
    "    # iterate over the annotations and split the timeseries in chunks\n",
    "    for key, df in data_frames.items():\n",
    "        chunks[key] += [df.iloc[int(annotation[\"start\"]*sample_rate):int(annotation[\"end\"]*sample_rate)] for i, annotation in y_user.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julio/opt/anaconda3/envs/master-project/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# append the activity label (as int) and the action id to the dataframe\n",
    "# we need to do this to be able to extract time series features later\n",
    "\n",
    "labels = y.loc[:, \"label\"].unique()\n",
    "label_ids = { l: i for l,i in zip(labels, range(0,len(labels))) }\n",
    "\n",
    "# list of tuples (left chunk, right chunk)\n",
    "chunks_two_handed = []\n",
    "# list of chunks\n",
    "chunks_one_handed = []\n",
    "\n",
    "y = y.replace(label_ids)\n",
    "\n",
    "\n",
    "for i, cl in zip(range(len(y)), y.iterrows()):\n",
    "    label_id = int(cl[1][\"label\"])\n",
    "    action_id = i\n",
    "    two_handed_chunk = []\n",
    "    for hand, chunk_list in chunks.items():\n",
    "        c = chunk_list[i]\n",
    "        chunk_hand = cl[1][\"hand\"]\n",
    "        #if chunk_hand == \"both\":\n",
    "        #c[\"activity\"] = label_id\n",
    "        #TODO for 2 phase classification: modify the label list\n",
    "        #else:\n",
    "             # use an id that's not yet used for another activity to label \"single handed\" activities\n",
    "        #    c[\"activity\"] = len(y)\n",
    "        #c[\"activity\"] = label_id\n",
    "        c[\"action_id\"] = action_id\n",
    "        two_handed_chunk.append(c)\n",
    "        if chunk_hand == hand:\n",
    "            #c[\"activity\"] = label_id\n",
    "            chunks_one_handed.append(c)\n",
    "    left_chunk = two_handed_chunk[0].reset_index()\n",
    "    right_chunk = two_handed_chunk[1].reset_index(drop=True)\n",
    "    right_chunk.drop(columns=[\"action_id\"], inplace=True)\n",
    "    right_chunk.columns = [str(col) + '_right' for col in right_chunk.columns]\n",
    "    two_handed_chunk = pd.concat([left_chunk, right_chunk], axis=1)\n",
    "    two_handed_chunk.set_index('index', inplace=True)\n",
    "    chunks_two_handed.append(two_handed_chunk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature extraction for 2 handed activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:  55%|█████▌    | 11/20 [01:51<01:30, 10.07s/it]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "labels = y.loc[:, \"label\"].squeeze()\n",
    "from features._timeseries_feature_extraction import extract_timeseries_features\n",
    "features_two_handed = extract_timeseries_features(pd.concat(chunks_two_handed).reset_index(drop=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "features_two_handed.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features_two_handed.dropna(inplace=True, axis=1)\n",
    "features_two_handed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: Feature selection & visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train models and score results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [('Logistic Regression', LogisticRegression(solver='liblinear', multi_class='ovr')), ('LDA', LinearDiscriminantAnalysis()), ('LinearSVC', LinearSVC()), ('CART', DecisionTreeClassifier()), ('NB', GaussianNB())]\n",
    "\n",
    "\n",
    "def classify_all(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    for name, model in models:\n",
    "        scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "        print(name, scores.mean())\n",
    "\n",
    "        # confusion matrix\n",
    "        y_pred = cross_val_predict(model, X_scaled, y, cv=5)\n",
    "        conf_mat = confusion_matrix(y, y_pred)\n",
    "        #print(conf_mat)\n",
    "        df_cm = pd.DataFrame(conf_mat, index = label_ids.keys(),\n",
    "                  columns = label_ids.keys())\n",
    "        df_cm[\"sum\"] = df_cm.sum(axis=1)\n",
    "        df_cm = df_cm.loc[:,label_ids.keys()].div(df_cm[\"sum\"], axis=0)\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sn.heatmap(df_cm, annot=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"Two handed classification\")\n",
    "classify_all(features_two_handed, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_two_handed,labels, test_size=0.2)\n",
    "m = models[0][1]\n",
    "m.fit(X_train, y_train)\n",
    "m.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}